# DisaggNet 自包含默认训练配置

project_name: "DisaggNet"

experiment:
  name: "baseline"

reproducibility:
  seed: 42
  deterministic: false
  benchmark: true

paths:
  output_dir: "outputs"
  data_dir: "Data"
  prepared_dir: "Data/prepared"

logging:
  save_dir: "logs/tensorboard"
  version: "v1"

data:
  batch_size: 512
  num_workers: 8
  pin_memory: true
  persistent_workers: false
  prefetch_factor: 2
  device_names: ["device_1"]
  window_size: 256

model:
  d_model: 256
  n_heads: 8
  num_layers: 6
  dropout: 0.1
  calibration:
    enable: true
    temperature_init: 1.0
  time_encoder:
    d_model: 256
    n_heads: 8
    num_layers: 6
    dropout: 0.1
    input_conv_embed: false
    causal_mask: true
  freq_encoder:
    enable: true
    proj_dim: 128
    conv1d_kernel: 3
    small_transformer_layers: 0
    dropout: 0.1
  fusion:
    type: "cross_attention"
    gated: true
  aux_encoder:
    enable: false
    hidden: 128
    dropout: 0.1
  heads:
    regression:
      hidden: 96
      dropout: 0.1
    classification:
      init_p: null

training:
  max_epochs: 100
  min_epochs: 1
  precision: "bf16-mixed"
  log_every_n_steps: 10
  gradient_clip_val: 0.5
  accumulate_grad_batches: 1
  check_val_every_n_epoch: 1
  accelerator: "auto"
  devices: auto
  monitor_device_stats: false
  visualization:
    enable: false
    plot_event_only: true
    max_plots_per_epoch: 0
  optimizer:
    name: "adamw"
    lr: 0.001
    weight_decay: 0.01
    betas: [0.9, 0.999]
  scheduler:
    name: "cosine"
    warmup_steps: 500
    T_max: 100
    eta_min: 1e-6
  checkpoint:
    dirpath: "outputs/checkpoints"
    filename: "epochepoch={epoch:02d}-v{version}"
    monitor: "val/score"
    mode: "max"
    save_top_k: 1
  early_stopping:
    enable: true
    monitor: "val/score"
    patience: 15
    mode: "max"
    min_delta: 0.001
  masking:
    window_strategy: "none"
    min_valid_ratio_time: 0.5
    min_valid_ratio_freq: 0.5
    combine_modalities: "min"
    downweight_power: 1.0
    epsilon: 0.0
  event_focus:
    enable: true
    weight: 2.0

loss:
  classification_weight: 2.0
  regression_weight: 1.0
  conservation_weight: 0.5
  consistency_weight: 1.0
  focal_alpha: 0.25
  focal_gamma: 2.0
  huber_delta: 1.0
  # 兼容旧版嵌套权重结构（若其他模块读取）
  weights:
    regression: 1.0
    classification: 2.0
    consistency_schedule:
      type: "linear"
      initial: 1.0
      final: 1.0
      warmup_epochs: 0
  regression:
    type: "mse"
    huber_delta: 1.0
    quantiles: [0.1, 0.5, 0.9]
  classification:
    type: "bce"
    pos_weight:
      enable: false
    focal_alpha: 0.25
    focal_gamma: 2.0
  priors:
    enable: false

evaluation:
  threshold_method: "optimal"
  zero_window_weight: 0.2
  test_after_training: false

imbalance_handling:
  use_weighted_sampling: true
  pos_weight_auto: true
  sampling_strategy: "mixed"

walk_forward:
  n_folds: 3
  purge_gap_minutes: 10
  val_span_days: 3.0
  test_span_days: 3.0
  min_train_days: 7.0
  segment_isolation: false
  holdout_test: true
  time_based_split: true

windowing:
  window_size: 1024
  stride: 512
  overlap: 0.5

conformal_prediction:
  enabled: false
  alpha: 0.1
  regression_method: "quantile"
  classification_method: "adaptive"

stability:
  numerical:
    detect_anomaly: false
  reproducibility:
    deterministic: false
    benchmark: true

debug:
  track_grad_norm: 0
  strict_validation: false
  log_model_graph: false