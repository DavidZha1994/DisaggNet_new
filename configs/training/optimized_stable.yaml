# DisaggNet 稳定优化配置（自包含，适配当前训练流水线）

project_name: "DisaggNet"

# 选择数据集（例如：UKDALE 或 REFIT）
dataset: "UKDALE"

experiment:
  name: "optimized_stable"

# 复现与稳定性
reproducibility:
  seed: 42
  deterministic: true
  benchmark: false

paths:
  output_dir: "outputs"
  data_dir: "Data"
  prepared_dir: "Data/prepared"

logging:
  save_dir: "logs/tensorboard"
  version: "stable"

# 数据设置（稳定版）
data:
  batch_size: 32
  num_workers: 0
  pin_memory: true
  persistent_workers: false
  prefetch_factor: null
  window_size: 256
  normalize_total_power_to_watts: true
  device_names:
    - washing_machine
    - dishwasher
    - kettle
    - microwave
    - fridge

# 模型设置（融合Transformer）
model:
  efficient_attention: true
  time_encoder:
    d_model: 96
    n_heads: 8
    num_layers: 3
    dropout: 0.2
    input_conv_embed: true
    causal_mask: true
    use_efficient_attention: true
    multi_scale_inputs:
      enable: false
      windows: [2, 4, 16, 64]
  freq_encoder:
    enable: true
    proj_dim: 256
    conv1d_kernel: 3
    dropout: 0.0
    use_transformer: false
    num_layers: 1
    n_heads: 4
    return_sequence: false
    use_efficient_attention: true
  fusion:
    type: "cross_attention"
    bidirectional: true
    gated: false
  aux_encoder:
    enable: false
    hidden: 128
    dropout: 0.1
  heads:
    regression:
      hidden: 192
      init_bias: 0.0
      use_softplus: false
      seq_use_softplus: true
      activation: "identity"
      seq_activation: "identity"
      gating_strength: 0.6
      gate_temperature: 0.9
      calib_strength: 0.15
    unknown:
      enable: false

# 训练设置（稳定优化）
training:
  max_epochs: 25
  min_epochs: 1
  precision: "32-true"
  log_every_n_steps: 10
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  check_val_every_n_epoch: 1
  accelerator: "auto"
  devices: 1
  monitor_device_stats: false
  visualization:
    enable: true
    plot_event_only: true
    max_plots_per_epoch: 10
    target_scale: 1.0
    # 交互可视化设置：将验证拼接输出为可交互HTML
    interactive: true
    save_dir: "outputs/viz"
  optimizer:
    name: "adamw"
    lr: 3e-4
    weight_decay: 0.0
    betas: [0.9, 0.999]
  scheduler:
    name: "cosine"
    warmup_steps: 2
    T_max: 25
    eta_min: 1e-6
  checkpoint:
    dirpath: "outputs/checkpoints"
    filename: "epochepoch={epoch:02d}-v{version}"
    monitor: "val/loss"
    mode: "min"
    save_top_k: 1
  early_stopping:
    enable: true
    monitor: "val/loss/total"
    patience: 10
    mode: "min"
    min_delta: 0.0
    start_epoch: 23
  masking:
    window_strategy: "none"
    min_valid_ratio_time: 0.5
    min_valid_ratio_freq: 0.5
    combine_modalities: "min"
    downweight_power: 1.0
    epsilon: 0.0
  event_focus:
    enable: false
    weight: 0.0

# 损失设置（优化版，含兼容字段）
loss:
  type: peak_aware
  regression_weight: 1.0
  classification_weight: 0.0
  conservation_weight: 0.4
  consistency_weight: 0.0
  nonneg_penalty_weight: 0.3
  # weights tuning
  #
  unknown_weight: 0.0
  unknown_match_weight: 1.0
  unknown_l1_penalty: 0.0
  huber_delta: 0.05
  normalize_per_device: false
  # 窗口尺度策略：与 overfit 脚本一致
  scale_strategy: window_quantile
  # Peak-Aware 参数（与脚本一致）
  peak_focus_top_p: 0.1
  peak_focus_weight: 0.6
  # 关闭其他归一化项权重
  active_threshold_rel: 0.015
  off_penalty_weight: 1.2
  rel_loss_weight: 0.0
  shape_loss_weight: 0.0
  derivative_loss_weight: 0.10
  edge_focus_weight: 0.40
  edge_focus_thr_rel: 0.03
  multiscale_shapes: []
  exclusive_penalty_weight: 0.15
  sparsity_weight: 0.02
  allocation_weight: 0.15
  allocation_blend_alpha: 0.0
  event_count_weight: 0.20
  active_amplitude_weight: 0.45
  shape_variance_weight: 0.15
  # 移除分类相关设置
  off_penalty_rel_threshold: 0.02
  # 课程式权重（翻转）：先回归，后分类
  reg_warmup_epochs: 15
  reg_warmup_scale: 4.0
  cls_start_epoch: 20
  unknown_start_epoch: 20
  unknown_ramp_epochs: 10
  cons_start_epoch: 2
  cons_ramp_epochs: 8
  off_start_epoch: 0
  off_ramp_epochs: 6
  peak_ramp_start: 10
  peak_ramp_epochs: 6
  peak_target_weight: 1.5
  edge_ramp_start: 10
  edge_ramp_epochs: 6
  edge_target_weight: 1.2
  derivative_ramp_start: 10
  derivative_ramp_epochs: 6
  derivative_target_weight: 1.2
  shape_ramp_start: 10
  shape_ramp_epochs: 6
  shape_target_weight: 0.8
  active_boost_start_epoch: 0
  active_boost_ramp_epochs: 0

# 评估设置
evaluation:
  threshold_method: "optimal"
  zero_window_weight: 0.1
  test_after_training: false

# 不平衡处理
imbalance_handling:
  use_weighted_sampling: true
  pos_weight_auto: false
  sampling_strategy: "oversample"
  pos_count_inverse_enable: false
  event_boost: 5.0
  early_oversample_epochs: 8
  early_event_boost: 1.5
  validity_min_ratio: 0.75

# Walk-Forward 交叉验证（优化版本）
walk_forward:
  n_folds: 5
  purge_gap_minutes: 15
  val_span_days: 5.0
  test_span_days: 5.0
  min_train_days: 10.0
  segment_isolation: true
  holdout_test: true
  time_based_split: true

# 窗口设置（数据准备参考）
windowing:
  window_size: 256
  stride: 128
  overlap: 0.5

# 共形预测（默认关闭）
conformal_prediction:
  enabled: false
  alpha: 0.1
  regression_method: "quantile"
  classification_method: "adaptive"

# 稳定性设置
stability:
  numerical:
    detect_anomaly: true
  reproducibility:
    deterministic: true
    benchmark: false

# 调试
debug:
  track_grad_norm: 2
  strict_validation: false
  log_model_graph: false
aux_training:
  metric_learning:
    enable: false
    use_power: true
    weight: 0.2
    margin: 0.2
    power_threshold_rel: 0.05
