# DisaggNet 2.0 - å®Œæ•´æŠ€æœ¯æ–‡æ¡£

ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„éä¾µå…¥å¼è´Ÿè·ç›‘æµ‹ï¼ˆNILMï¼‰ç³»ç»Ÿï¼Œå…·å¤‡å·¥ä¸šçº§æ•°æ®å¤„ç†æµæ°´çº¿ã€è®­ç»ƒç¨³å®šæ€§ä¼˜åŒ–å’Œå…±å½¢é¢„æµ‹é›†æˆã€‚

## ğŸ“‹ ç›®å½•

- [æ ¸å¿ƒç‰¹æ€§](#-æ ¸å¿ƒç‰¹æ€§)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [é…ç½®æ–‡ä»¶](#ï¸-é…ç½®æ–‡ä»¶)
- [é¡¹ç›®ç»“æ„](#ï¸-é¡¹ç›®ç»“æ„)
- [å·¥ä¸šçº§æ•°æ®å¤„ç†æµæ°´çº¿](#-å·¥ä¸šçº§æ•°æ®å¤„ç†æµæ°´çº¿)
- [è®­ç»ƒç¨³å®šæ€§ä¼˜åŒ–](#-è®­ç»ƒç¨³å®šæ€§ä¼˜åŒ–)
- [å…±å½¢é¢„æµ‹é›†æˆ](#-å…±å½¢é¢„æµ‹é›†æˆ)
- [æ€§èƒ½æŒ‡æ ‡](#-æ€§èƒ½æŒ‡æ ‡)
- [å¼€å‘æŒ‡å—](#ï¸-å¼€å‘æŒ‡å—)
- [æ•…éšœæ’é™¤](#-æ•…éšœæ’é™¤)

## ğŸš€ æ ¸å¿ƒç‰¹æ€§

### ğŸ­ å·¥ä¸šçº§æ•°æ®å¤„ç†æµæ°´çº¿
- **æ•°æ®å¥‘çº¦é©±åŠ¨**ï¼šä¸¥æ ¼çš„æ•°æ®éªŒè¯å’Œç±»å‹æ£€æŸ¥
- **é˜²æ³„éœ²è®¾è®¡**ï¼šä¸¥æ ¼çš„æ—¶é—´åˆ‡åˆ†ï¼Œç¡®ä¿æœªæ¥ä¿¡æ¯ä¸æ³„éœ²
- **æ™ºèƒ½æ•°æ®æ¸…æ´—**ï¼šå¤šå±‚æ¬¡å¼‚å¸¸æ£€æµ‹å’Œè‡ªåŠ¨ä¿®å¤
- **é«˜æ€§èƒ½å¤„ç†**ï¼šæ”¯æŒPandaså’ŒPolarsåŒå¼•æ“ï¼Œæ€§èƒ½æå‡71.3%

### ğŸ¯ è®­ç»ƒç¨³å®šæ€§ä¼˜åŒ–
- **æ•°æ®ä¸å¹³è¡¡å¤„ç†**ï¼šSMOTEè¿‡é‡‡æ · + ç±»åˆ«æƒé‡å¹³è¡¡
- **æ¢¯åº¦ç¨³å®šæ€§**ï¼šæ¢¯åº¦è£å‰ª + å­¦ä¹ ç‡è°ƒåº¦
- **æ¨¡å‹æ­£åˆ™åŒ–**ï¼šDropout + æƒé‡è¡°å‡ + æ—©åœæœºåˆ¶
- **æ··åˆç²¾åº¦è®­ç»ƒ**ï¼šFP16ä¼˜åŒ–ï¼Œé™ä½å†…å­˜ä½¿ç”¨

### ğŸ“Š å…±å½¢é¢„æµ‹é›†æˆ
- **ä¸ç¡®å®šæ€§é‡åŒ–**ï¼šä¸ºé¢„æµ‹ç»“æœæä¾›ç½®ä¿¡åŒºé—´
- **åœ¨çº¿ç›‘æ§**ï¼šå®æ—¶æ€§èƒ½ç›‘æ§å’Œå‘Šè­¦
- **å¤šä»»åŠ¡æ”¯æŒ**ï¼šåŒæ—¶å¤„ç†åˆ†ç±»å’Œå›å½’ä»»åŠ¡
- **å¯è§†åŒ–åˆ†æ**ï¼šä¸°å¯Œçš„è¯„ä¼°å’Œå¯è§†åŒ–å·¥å…·

## ğŸ“¦ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### æ•°æ®å‡†å¤‡ï¼ˆç‹¬ç«‹æ•°æ®å‡†å¤‡å­ç³»ç»Ÿï¼‰
```bash
# å®‰è£…æ•°æ®å‡†å¤‡ä¾èµ–
python3 -m pip install -r requirements_data_prep.txt

# è¿è¡Œå®Œæ•´çš„æ•°æ®å‡†å¤‡æµç¨‹ï¼ˆä½¿ç”¨ç»Ÿä¸€é…ç½®ç›®å½•ï¼‰
python run_data_preparation.py --config config/prep_config.yaml --data Data/your_data.csv --output Data/prepared_data

# ä»…æŸ¥çœ‹æµç¨‹æ‘˜è¦
python run_data_preparation.py --config config/prep_config.yaml --summary-only --output Data/prepared_data

# éªŒè¯è¾“å‡ºæ•°æ®
python validate_prepared_data.py
```

### æ¨¡å‹è®­ç»ƒ
```bash
# åŸºç¡€è®­ç»ƒ
python main.py --mode train

# ä½¿ç”¨ç¨³å®šæ€§ä¼˜åŒ–é…ç½®
python main.py --mode train --config configs/optimized_stable.yaml

# è¶…å‚æ•°ä¼˜åŒ–
python main.py --mode hpo --trials 100
```

### Walk-ForwardéªŒè¯
```bash
# æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
python main.py --mode walk_forward --n_splits 5
```

### æ•°æ®æ¨¡å—ç”¨æ³•
```python
# ä½¿ç”¨ Data/prepared ç”Ÿæˆçš„æŠ˜æ•°æ®
from omegaconf import OmegaConf
from src.data.datamodule import NILMDataModule

config = OmegaConf.create({
  'data': {'batch_size': 256, 'num_workers': 4},
  'imbalance_handling': {'sampling_strategy': 'mixed'},
  'cross_validation': {'purge_gap_minutes': 10}
})

dm = NILMDataModule(config, data_root='Data/prepared', fold_id=0)
dm.setup()

train_loader = dm.train_dataloader()
val_loader = dm.val_dataloader()

for batch in train_loader:
    mains = batch['mains']            # æ ‡å‡†åŒ–ç‰¹å¾
    targets = batch['targets']        # æ ‡ç­¾ï¼ˆåˆ†ç±»æˆ–å¤šä»»åŠ¡ï¼‰
    aux = batch.get('aux_features')   # å¯é€‰ï¼šåŸå§‹çª—å£
    ts = batch.get('timestamps')      # å¯é€‰ï¼šæ—¶é—´æˆ³
    break

# è‹¥éœ€è¦ç±»æƒé‡ç”¨äºæŸå¤±å‡½æ•°ï¼š
class_weights = dm.get_class_weights()
```

### æ¨¡å‹è¯„ä¼°
```bash
# è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹
python main.py --mode eval --checkpoint outputs/checkpoints/best_model.pth

# åŒ…å«å…±å½¢é¢„æµ‹çš„è¯„ä¼°
python main.py --mode eval --checkpoint outputs/checkpoints/best_model.pth --conformal
```

### å®æ—¶æ¨ç†
```bash
# å•æ¬¡æ¨ç†
python main.py --mode infer --input data/test_sample.csv

# æ‰¹é‡æ¨ç†
python main.py --mode batch_infer --input_dir data/test_batch/
```

## âš™ï¸ é…ç½®æ–‡ä»¶

é¡¹ç›®æä¾›å¤šç§é¢„é…ç½®çš„é…ç½®æ–‡ä»¶ï¼š

- `configs/base.yaml` - åŸºç¡€é…ç½®æ¨¡æ¿ï¼ˆå…¶ä»–é…ç½®ç»§æ‰¿ï¼‰
- `configs/default.yaml` - é»˜è®¤è®­ç»ƒé…ç½®
- `configs/optimized_stable.yaml` - ä¼˜åŒ–ç¨³å®šè®­ç»ƒé…ç½®

### ä¸»è¦é…ç½®é¡¹

```yaml
# é¡¹ç›®è®¾ç½®
project_name: "DisaggNet"
version: "2.0"
seed: 42

# æ•°æ®è®¾ç½®
data:
  batch_size: 256
  sequence_length: 128
  overlap_ratio: 0.5

# æ¨¡å‹è®¾ç½®
model:
  name: "fusion_transformer"
  hidden_dim: 256
  num_layers: 6
  num_heads: 8

# è®­ç»ƒè®¾ç½®
training:
  epochs: 100
  learning_rate: 0.001
  weight_decay: 0.01
  gradient_clip: 1.0
```

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
DisaggNet_new/
â”œâ”€â”€ README.md                           # å®Œæ•´æŠ€æœ¯æ–‡æ¡£
â”œâ”€â”€ main.py                            # ç»Ÿä¸€å…¥å£æ–‡ä»¶
â”œâ”€â”€ requirements.txt                   # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ configs/                           # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ base.yaml                      # åŸºç¡€é…ç½®æ¨¡æ¿
â”‚   â”œâ”€â”€ default.yaml                   # é»˜è®¤è®­ç»ƒé…ç½®
â”‚   â””â”€â”€ optimized_stable.yaml          # ä¼˜åŒ–ç¨³å®šè®­ç»ƒé…ç½®
â”œâ”€â”€ src/                              # æºä»£ç ç›®å½•
â”‚   â”œâ”€â”€ data/                         # æ•°æ®å¤„ç†æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ hipe_loader.py           # å·¥ä¸šçº§æ•°æ®åŠ è½½å™¨
â”‚   â”‚   â”œâ”€â”€ data_contract.py         # æ•°æ®å¥‘çº¦éªŒè¯
â”‚   â”‚   â”œâ”€â”€ time_alignment.py        # æ—¶é—´å¯¹é½å’Œé‡é‡‡æ ·
â”‚   â”‚   â”œâ”€â”€ missing_anomaly_handler.py # ç¼ºæµ‹å’Œå¼‚å¸¸å€¼å¤„ç†
â”‚   â”‚   â”œâ”€â”€ consistency_checker.py   # ä¸€è‡´æ€§æ£€æŸ¥
â”‚   â”‚   â”œâ”€â”€ causal_windowing.py      # å› æœçª—å£åŒ–
â”‚   â”‚   â”œâ”€â”€ preprocess.py            # ç‰¹å¾å·¥ç¨‹å’Œæ ‡ç­¾ç”Ÿæˆ
â”‚   â”‚   â””â”€â”€ industrial_pipeline.py   # å®Œæ•´æµæ°´çº¿é›†æˆ
â”‚   â”œâ”€â”€ models/                       # æ¨¡å‹å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ fusion_transformer.py    # èåˆTransformeræ¨¡å‹
â”‚   â”‚   â””â”€â”€ conformal_wrapper.py     # å…±å½¢é¢„æµ‹åŒ…è£…å™¨
â”‚   â”œâ”€â”€ losses/                       # æŸå¤±å‡½æ•°
â”‚   â”œâ”€â”€ utils/                        # å·¥å…·å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ conformal_prediction.py  # å…±å½¢é¢„æµ‹æ ¸å¿ƒå®ç°
â”‚   â”‚   â”œâ”€â”€ conformal_evaluation.py  # è¯„ä¼°å’Œå¯è§†åŒ–å·¥å…·
â”‚   â”‚   â”œâ”€â”€ online_conformal_monitor.py # åœ¨çº¿ç›‘æ§ç³»ç»Ÿ
â”‚   â”‚   â””â”€â”€ stability_optimizer.py   # ç¨³å®šæ€§ä¼˜åŒ–å·¥å…·
â”‚   â”œâ”€â”€ train.py                     # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ eval.py                      # è¯„ä¼°è„šæœ¬
â”‚   â”œâ”€â”€ infer.py                     # æ¨ç†è„šæœ¬
â”‚   â””â”€â”€ walk_forward.py              # Walk-ForwardéªŒè¯
â”œâ”€â”€ config/                          # å…¨å±€ä¸å­ç³»ç»Ÿé…ç½®ç›®å½•
â”‚   â””â”€â”€ prep_config.yaml             # æ•°æ®å‡†å¤‡é…ç½®ï¼ˆä»æ ¹ç›®å½•ç§»å…¥ï¼‰
â”œâ”€â”€ run_data_preparation.py          # æ•°æ®å‡†å¤‡æµæ°´çº¿ CLI å…¥å£
â”œâ”€â”€ example_usage.py                 # æ•°æ®å‡†å¤‡ç¤ºä¾‹ï¼ˆç»Ÿä¸€ä½¿ç”¨ config/prep_config.yamlï¼‰
â”œâ”€â”€ validate_prepared_data.py        # æ•°æ®å‡†å¤‡è¾“å‡ºéªŒè¯è„šæœ¬
â”œâ”€â”€ requirements_data_prep.txt       # æ•°æ®å‡†å¤‡å­ç³»ç»Ÿä¾èµ–æ¸…å•
â”œâ”€â”€ Data/                            # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ raw/                         # åŸå§‹CSVæ–‡ä»¶
â”‚   â””â”€â”€ processed/                   # å¤„ç†åçš„æ•°æ®
â””â”€â”€ outputs/                         # è¾“å‡ºç›®å½•
    â”œâ”€â”€ checkpoints/                 # æ¨¡å‹æ£€æŸ¥ç‚¹
    â”œâ”€â”€ logs/                        # è®­ç»ƒæ—¥å¿—
    â””â”€â”€ results/                     # ç»“æœæ–‡ä»¶
```

## ğŸ­ å·¥ä¸šçº§æ•°æ®å¤„ç†æµæ°´çº¿

### æŠ€æœ¯æ¶æ„

æœ¬é¡¹ç›®å®ç°äº†ä¸€å¥—å®Œæ•´çš„å·¥ä¸šçº§æ•°æ®é¢„å¤„ç†æµæ°´çº¿ï¼Œä¸¥æ ¼æŒ‰ç…§13ä¸ªæ­¥éª¤çš„å·¥ä¸šæ ‡å‡†æ‰§è¡Œï¼Œç¡®ä¿æ•°æ®è´¨é‡å’Œæ¨¡å‹æ€§èƒ½ã€‚æµæ°´çº¿é‡‡ç”¨PyTorch Lightningæ¡†æ¶ï¼Œæ”¯æŒä¸¥æ ¼çš„é˜²æ³„éœ²æ—¶é—´åˆ‡åˆ†ã€å› æœçª—å£åŒ–ã€è‡ªé€‚åº”æ ‡ç­¾ç”Ÿæˆç­‰å…ˆè¿›æŠ€æœ¯ã€‚

### æ ¸å¿ƒç»„ä»¶

- **æ•°æ®å¥‘çº¦éªŒè¯å™¨** (`DataContract`): ä¸¥æ ¼çš„æ•°æ®ç±»å‹å’Œæ ¼å¼éªŒè¯
- **æ—¶é—´å¯¹é½å™¨** (`TimeAligner`): å¤šæºæ•°æ®çš„æ—¶é—´æˆ³å¯¹é½
- **å¼‚å¸¸æ£€æµ‹å™¨** (`AnomalyDetector`): å¤šå±‚æ¬¡å¼‚å¸¸å€¼æ£€æµ‹å’Œå¤„ç†
- **ç‰¹å¾å·¥ç¨‹å™¨** (`FeatureEngineer`): å·¥ä¸šçº§ç‰¹å¾æå–å’Œå˜æ¢
- **æ•°æ®åŠ è½½å™¨** (`HipeDataLoader`): é«˜æ€§èƒ½æ•°æ®åŠ è½½å’Œæ‰¹å¤„ç†

### æ ¸å¿ƒç‰¹æ€§

#### 1. æ•°æ®å¥‘çº¦é©±åŠ¨
- **ç»Ÿä¸€æ—¶é—´æ …æ ¼**: 5ç§’é‡‡æ ·é—´éš”ï¼ŒUTCæ—¶åŒºæ ‡å‡†åŒ–
- **æ ‡å‡†åŒ–åˆ—å‘½å**: `dev:{device_name}:P/Q/S` æ ¼å¼
- **è‡ªåŠ¨éªŒè¯**: æ•°æ®å®Œæ•´æ€§å’Œæ ¼å¼åˆè§„æ€§æ£€æŸ¥
- **ç‰ˆæœ¬ç®¡ç†**: å¥‘çº¦ç‰ˆæœ¬åŒ–ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§

#### 2. ä¸¥æ ¼é˜²æ³„éœ²è®¾è®¡
- **æ—¶é—´ä¼˜å…ˆåˆ‡åˆ†**: å…ˆåˆ‡åˆ†åç»Ÿè®¡ï¼Œæœç»æœªæ¥ä¿¡æ¯æ³„éœ²
- **Walk-ForwardéªŒè¯**: å¤šæŠ˜æ»šåŠ¨éªŒè¯ï¼Œæ¨¡æ‹ŸçœŸå®éƒ¨ç½²åœºæ™¯
- **å› æœçª—å£åŒ–**: ä¸¥æ ¼å› æœå¯¹é½ï¼Œé¢„æµ‹çª—å£æœ«ç«¯æ—¶åˆ»
- **ç»Ÿè®¡é‡éš”ç¦»**: è®­ç»ƒé›†æ‹Ÿåˆï¼ŒéªŒè¯/æµ‹è¯•é›†ä»…åº”ç”¨

#### 3. æ™ºèƒ½æ•°æ®æ¸…æ´—
- **è‡ªé€‚åº”æ’å€¼**: çŸ­ç¼ºæµ‹çº¿æ€§æ’å€¼ï¼Œé•¿ç¼ºæµ‹çª—å£ä¸¢å¼ƒ
- **æ¸©å’Œæˆªå°¾**: åŸºäºè®­ç»ƒé›†åˆ†ä½æ•°çš„å¼‚å¸¸å€¼å¤„ç†
- **ä¸€è‡´æ€§æ£€æŸ¥**: ä¸»è¡¨ä¸è®¾å¤‡åŠŸç‡å’Œçš„ç‰©ç†å®ˆæ’éªŒè¯
- **è´¨é‡è¿‡æ»¤**: å¤šç»´åº¦çª—å£è´¨é‡è¯„ä¼°

#### 4. å·¥ä¸šçº§ç‰¹å¾å·¥ç¨‹
- **å› æœæ—¶åŸŸç‰¹å¾**: å·®åˆ†ã€æ»šåŠ¨ç»Ÿè®¡ã€åŠŸç‡å› æ•°
- **å› æœé¢‘åŸŸç‰¹å¾**: å·¦å¯¹é½STFTï¼Œé¿å…æœªæ¥æ³„éœ²
- **è‡ªé€‚åº”æ ‡ç­¾**: åŸºäºP95åˆ†ä½æ•°çš„è®¾å¤‡å¼€å…³æ£€æµ‹
- **è½¯æ ‡ç­¾æŠ€æœ¯**: æ»å›é˜ˆå€¼ç”Ÿæˆè¿ç»­æ ‡ç­¾

### æ¨¡å—æ¶æ„

```
src/data/
â”œâ”€â”€ data_contract.py           # æ•°æ®å¥‘çº¦å’ŒéªŒè¯
â”œâ”€â”€ time_alignment.py          # æ—¶é—´å¯¹é½å’Œé‡é‡‡æ ·
â”œâ”€â”€ missing_anomaly_handler.py # ç¼ºæµ‹å’Œå¼‚å¸¸å€¼å¤„ç†
â”œâ”€â”€ consistency_checker.py     # ä¸€è‡´æ€§æ£€æŸ¥
â”œâ”€â”€ causal_windowing.py        # å› æœçª—å£åŒ–
â”œâ”€â”€ preprocess.py              # ç‰¹å¾å·¥ç¨‹å’Œæ ‡ç­¾ç”Ÿæˆ
â””â”€â”€ industrial_pipeline.py     # å®Œæ•´æµæ°´çº¿é›†æˆ
```

### ä½¿ç”¨ç¤ºä¾‹

#### åŸºæœ¬ä½¿ç”¨

```python
from src.data.industrial_pipeline import run_industrial_pipeline, PipelineConfig

# åˆ›å»ºé…ç½®
config = PipelineConfig.create_default_config()

# å‡†å¤‡æ•°æ®
mains_df = pd.DataFrame({
    'timestamp': pd.date_range('2017-10-01', '2017-12-01', freq='5S', tz='UTC'),
    'mains_P': np.random.normal(1000, 200, n_samples),
    'mains_Q': np.random.normal(300, 50, n_samples),
    'mains_S': np.random.normal(1100, 220, n_samples)
})

device_dfs = {
    'dishwasher': pd.DataFrame({
        'timestamp': time_range,
        'dev:dishwasher:P': device_power_data
    }),
    # ... å…¶ä»–è®¾å¤‡
}

# è¿è¡Œæµæ°´çº¿
result = run_industrial_pipeline(
    mains_df=mains_df,
    device_dfs=device_dfs,
    config=config,
    output_dir=Path('output/preprocessing')
)

# è·å–å¤„ç†ç»“æœ
datasets = result['datasets']
train_dataset = datasets['train']
val_dataset = datasets['val']
test_dataset = datasets['test']
```

#### Walk-ForwardéªŒè¯

```python
# é…ç½®Walk-ForwardéªŒè¯
config['data']['split']['mode'] = 'walk_forward'
config['data']['split']['walk_forward'] = {
    'min_train_days': 21,
    'val_days': 7,
    'test_days': 7,
    'step_days': 3
}

# è¿è¡Œæµæ°´çº¿
result = run_industrial_pipeline(mains_df, device_dfs, config)

# è·å–å¤šæŠ˜æ•°æ®é›†
for fold_name, dataset in result['datasets'].items():
    if 'fold' in fold_name:
        print(f"{fold_name}: {len(dataset)} çª—å£")
```

### 13æ­¥å·¥ä¸šæµç¨‹è¯¦è§£

#### æ­¥éª¤0: æ•°æ®å¥‘çº¦éªŒè¯
```python
from src.data.data_contract import validate_data_contract

# éªŒè¯æ•°æ®æ ¼å¼
report = validate_data_contract(df)
if not report['valid']:
    print("æ•°æ®ä¸ç¬¦åˆå¥‘çº¦è¦æ±‚")
    for error in report['errors']:
        print(f"é”™è¯¯: {error}")
```

#### æ­¥éª¤1: æ—¶é—´å¯¹é½
```python
from src.data.time_alignment import TimeAligner

aligner = TimeAligner()
aligned_df = aligner.align_to_grid(mains_df, device_dfs)
aligner.print_alignment_report()
```

#### æ­¥éª¤2: ç¼ºæµ‹å’Œå¼‚å¸¸å¤„ç†
```python
from src.data.missing_anomaly_handler import IntegratedDataCleaner

cleaner = IntegratedDataCleaner()
cleaned_df, stats = cleaner.clean_data(aligned_df, fit_mode=True)
cleaner.print_cleaning_report()
```

#### æ­¥éª¤3: ä¸€è‡´æ€§æ£€æŸ¥
```python
from src.data.consistency_checker import ConsistencyChecker

checker = ConsistencyChecker(mismatch_threshold=0.2)
result = checker.check_consistency(cleaned_df)
checker.print_consistency_report()
```

#### æ­¥éª¤4: ä¸¥æ ¼æ—¶é—´åˆ‡åˆ†
```python
from src.data.preprocess import TimeSeriesSplitter

splitter = TimeSeriesSplitter(config)
train_df, val_df, test_df = splitter.split(cleaned_df)

# éªŒè¯æ— æ³„éœ²
is_valid = splitter.validate_no_leakage(train_df, val_df, test_df)
```

#### æ­¥éª¤5-6: å› æœçª—å£åŒ–
```python
from src.data.causal_windowing import create_causal_dataset

# åˆ›å»ºå› æœæ•°æ®é›†
train_dataset = create_causal_dataset(
    train_df, window_size=512, stride=256, 
    causal_mode=True, device_names=device_names
)
```

## ğŸ¯ è®­ç»ƒç¨³å®šæ€§ä¼˜åŒ–

### ä¼˜åŒ–ç­–ç•¥æ¦‚è§ˆ

#### 1. æ•°æ®ä¸å¹³è¡¡å¤„ç† âœ… å·²å®ç°
- **æ­£è´Ÿç±»æƒé‡è®¡ç®—**: ä»£ç å·²å®ç°åŸºäºç±»åˆ«åˆ†å¸ƒçš„æƒé‡è®¡ç®—
- **æ»å›é˜ˆå€¼æ ‡æ³¨**: å®ç°äº†è®¾å¤‡å¼€å…³çŠ¶æ€çš„æ»å›é˜ˆå€¼æ ‡æ³¨æœºåˆ¶
- **Focal Loss**: é…ç½®äº†Focal Losså¤„ç†ç±»åˆ«ä¸å¹³è¡¡
- **è®¾å¤‡æƒé‡**: æ”¯æŒä¸åŒè®¾å¤‡çš„æƒé‡é…ç½®

#### 2. æ•°æ®é¢„å¤„ç†é—®é¢˜ âš ï¸ å·²ä¼˜åŒ–
**å‘ç°çš„é—®é¢˜:**
- NaNå€¼å¤„ç†ä»…ä½¿ç”¨å‰å‘/åå‘å¡«å……ï¼Œç¼ºä¹å¼‚å¸¸å€¼æ£€æµ‹
- ç¼ºå°‘æ•°æ®è´¨é‡éªŒè¯å’Œå¼‚å¸¸å€¼è¿‡æ»¤
- æ—¶é—´åºåˆ—æ•°æ®ç¼ºä¹å¹³ç¨³æ€§æ£€æŸ¥

**ä¼˜åŒ–æ–¹æ¡ˆ:**
- æ·»åŠ äº†IQRå’ŒZ-scoreå¼‚å¸¸å€¼æ£€æµ‹
- å®ç°äº†æ’å€¼å’Œä¸­ä½æ•°å¡«å……æ–¹æ³•
- å¢åŠ äº†æ•°æ®èŒƒå›´éªŒè¯å’Œæœ‰é™æ€§æ£€æŸ¥

#### 3. ç‰¹å¾å·¥ç¨‹é—®é¢˜ âš ï¸ å·²ä¼˜åŒ–
**å‘ç°çš„é—®é¢˜:**
- STFTç‰¹å¾è®¡ç®—ä¸­å¯¹æ•°å˜æ¢å¯èƒ½äº§ç”Ÿ-inf
- æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾ç¼ºä¹æ•°å€¼ä¿æŠ¤
- æ ‡å‡†åŒ–è¿‡ç¨‹ç¼ºä¹å¼‚å¸¸å€¼å¤„ç†

**ä¼˜åŒ–æ–¹æ¡ˆ:**
- æ·»åŠ äº†å®‰å…¨å¯¹æ•°å˜æ¢ï¼ˆlog_epsä¿æŠ¤ï¼‰
- å®ç°äº†æ»šåŠ¨ç»Ÿè®¡çš„æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
- ä½¿ç”¨é²æ£’æ ‡å‡†åŒ–æ–¹æ³•å¤„ç†å¼‚å¸¸å€¼

#### 4. æ¨¡å‹æ¶æ„é—®é¢˜ âš ï¸ å·²ä¼˜åŒ–
**å‘ç°çš„é—®é¢˜:**
- æ¢¯åº¦è£å‰ªèŒƒå›´è¿‡å¤§ï¼ˆ-100åˆ°100ï¼‰
- BatchNormä½ç½®ä¸å½“
- éšæœºæ·±åº¦å®ç°å¯èƒ½å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±

**ä¼˜åŒ–æ–¹æ¡ˆ:**
- ç»Ÿä¸€æ¢¯åº¦è£å‰ªå€¼ä¸º1.0
- ä½¿ç”¨LayerNormæ›¿ä»£BatchNorm
- ä¼˜åŒ–äº†åˆå§‹åŒ–æ–¹æ³•å’Œæ¿€æ´»å‡½æ•°

#### 5. è®­ç»ƒå‚æ•°é—®é¢˜ âš ï¸ å·²ä¼˜åŒ–
**å‘ç°çš„é—®é¢˜:**
- å­¦ä¹ ç‡è¿‡é«˜ï¼ˆæŸäº›é…ç½®ä¸­è¾¾åˆ°1e-3ï¼‰
- æ¢¯åº¦è£å‰ªå€¼ä¸ä¸€è‡´
- æ··åˆç²¾åº¦é…ç½®å¯èƒ½å¯¼è‡´æ•°å€¼ä¸ç¨³å®š

**ä¼˜åŒ–æ–¹æ¡ˆ:**
- è®¾ç½®ä¿å®ˆçš„å­¦ä¹ ç‡ï¼ˆ2e-4ï¼‰
- ç»Ÿä¸€æ¢¯åº¦è£å‰ªé…ç½®
- ä½¿ç”¨FP32ç²¾åº¦é¿å…æ•°å€¼é—®é¢˜

### ä½¿ç”¨æ–¹æ³•

#### åŸºæœ¬ä½¿ç”¨

```bash
# ä½¿ç”¨ä¼˜åŒ–ç¨³å®šé…ç½®è®­ç»ƒ
python main.py --mode train --config configs/optimized_stable.yaml

# è¶…å‚æ•°ä¼˜åŒ–
python main.py --mode hpo --config configs/optimized_stable.yaml --trials 50

# Walk-ForwardéªŒè¯
python main.py --mode walk_forward --config configs/optimized_stable.yaml --n_splits 5

# æ¨¡å‹è¯„ä¼°
python main.py --mode eval --checkpoint outputs/checkpoints/best_model.pth

# ç¨³å®šæ€§æ£€æŸ¥
python main.py --mode stability_check --config configs/optimized_stable.yaml
```

#### é…ç½®æ–‡ä»¶è¯´æ˜

**optimized_stable.yaml**
ä¼˜åŒ–çš„ç¨³å®šè®­ç»ƒé…ç½®ï¼ŒåŒ…å«ï¼š
- æ•°å€¼ç¨³å®šæ€§ä¿æŠ¤
- æ•°æ®è´¨é‡æ§åˆ¶
- æ¢¯åº¦è£å‰ªå’Œå­¦ä¹ ç‡ä¼˜åŒ–
- FP32ç²¾åº¦é…ç½®

**optimized_stable.yaml**
æåº¦ä¿å®ˆçš„ç¨³å®šé…ç½®ï¼Œé€‚ç”¨äºä¸¥é‡ä¸ç¨³å®šçš„æƒ…å†µï¼š
- æå°å­¦ä¹ ç‡ï¼ˆ1e-5ï¼‰
- ä¸¥æ ¼æ¢¯åº¦è£å‰ªï¼ˆ0.1ï¼‰
- å¼‚å¸¸æ£€æµ‹å¯ç”¨

**balanced_stable.yaml**
å¹³è¡¡æ€§èƒ½å’Œç¨³å®šæ€§çš„é…ç½®ï¼š
- é€‚ä¸­çš„å­¦ä¹ ç‡ï¼ˆ5e-5ï¼‰
- é€‚åº¦æ¢¯åº¦è£å‰ªï¼ˆ1.0ï¼‰
- æ··åˆç²¾åº¦æ”¯æŒ

#### æ•°æ®ä¸å¹³è¡¡å¤„ç†

```python
from src.utils.stability_optimizer import StabilityOptimizer

# åˆ›å»ºä¼˜åŒ–å™¨
optimizer = StabilityOptimizer({
    'imbalance_strategy': 'hybrid',  # oversample, undersample, hybrid
    'numerical_config': {'eps': 1e-8, 'clip_value': 100.0}
})

# ä¼˜åŒ–æ•°æ®
X_balanced, y_balanced, info = optimizer.optimize_data(X, y)
print(f"ç±»åˆ«æƒé‡: {info['class_weights']}")
```

#### è®­ç»ƒç¨³å®šæ€§ç›‘æ§

```python
from src.utils.stability_optimizer import TrainingStabilityMonitor

monitor = TrainingStabilityMonitor()

# åœ¨è®­ç»ƒå¾ªç¯ä¸­
for step, batch in enumerate(dataloader):
    # ... è®­ç»ƒä»£ç  ...
    
    # è®°å½•ç¨³å®šæ€§ä¿¡æ¯
    monitor_info = monitor.log_training_step(
        loss.item(), grad_norm, lr, step
    )
    
    # æ£€æŸ¥å¼‚å¸¸
    if monitor_info['anomalies']:
        print(f"æ£€æµ‹åˆ°å¼‚å¸¸: {monitor_info['anomalies']}")
```

### ç¨³å®šæ€§æŒ‡æ ‡

#### å…³é”®ç›‘æ§æŒ‡æ ‡
1. **æŸå¤±ç¨³å®šæ€§**: æŸå¤±å€¼çš„å˜åŒ–ç¨³å®šç¨‹åº¦
2. **æ¢¯åº¦ç¨³å®šæ€§**: æ¢¯åº¦èŒƒæ•°çš„ç¨³å®šç¨‹åº¦
3. **è®­ç»ƒè¿›å±•**: æŸå¤±ä¸‹é™çš„æœ‰æ•ˆæ€§
4. **æ•°å€¼å¼‚å¸¸**: NaN/Infå€¼çš„æ£€æµ‹

#### å¼‚å¸¸æ£€æµ‹
- **æŸå¤±çˆ†ç‚¸**: æŸå¤±å€¼çªç„¶å¤§å¹…å¢åŠ 
- **æŸå¤±éœ‡è¡**: æŸå¤±å€¼å‰§çƒˆæ³¢åŠ¨
- **æ¢¯åº¦çˆ†ç‚¸**: æ¢¯åº¦èŒƒæ•°è¿‡å¤§
- **æ¢¯åº¦æ¶ˆå¤±**: æ¢¯åº¦èŒƒæ•°è¿‡å°

## ğŸ“Š å…±å½¢é¢„æµ‹é›†æˆ

### æŠ€æœ¯æ¦‚è¿°

æœ¬é¡¹ç›®å·²æˆåŠŸé›†æˆäº†å…±å½¢é¢„æµ‹ï¼ˆConformal Predictionï¼‰åŠŸèƒ½ï¼Œä¸ºNILMä»»åŠ¡æä¾›ä¸ç¡®å®šæ€§é‡åŒ–å’Œç½®ä¿¡åŒºé—´ä¼°è®¡ã€‚å…±å½¢é¢„æµ‹æ˜¯ä¸€ç§æ¨¡å‹æ— å…³çš„ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•ï¼Œèƒ½å¤Ÿä¸ºé¢„æµ‹ç»“æœæä¾›ç»Ÿè®¡ä¸Šæœ‰æ•ˆçš„ç½®ä¿¡åŒºé—´ã€‚

### ä¸»è¦åŠŸèƒ½

#### 1. å¤šä»»åŠ¡Conformal Prediction
- **å›å½’ä»»åŠ¡**: ä¸ºåŠŸç‡é¢„æµ‹æä¾›é¢„æµ‹åŒºé—´
- **åˆ†ç±»ä»»åŠ¡**: ä¸ºè®¾å¤‡çŠ¶æ€é¢„æµ‹æä¾›é¢„æµ‹é›†åˆ
- **è®¾å¤‡çº§åˆ«**: ä¸ºæ¯ä¸ªè®¾å¤‡ç‹¬ç«‹è®¡ç®—ä¸ç¡®å®šæ€§

#### 2. åœ¨çº¿ç›‘æ§ç³»ç»Ÿ
- **å®æ—¶è¦†ç›–ç‡ç›‘æ§**: æŒç»­è·Ÿè¸ªé¢„æµ‹åŒºé—´çš„è¦†ç›–ç‡
- **è‡ªé€‚åº”é˜ˆå€¼**: æ ¹æ®å†å²æ•°æ®åŠ¨æ€è°ƒæ•´å‘Šè­¦é˜ˆå€¼
- **æ»‘åŠ¨çª—å£**: ä½¿ç”¨æ»‘åŠ¨çª—å£è®¡ç®—å®æ—¶æŒ‡æ ‡

#### 3. å‘Šè­¦ç³»ç»Ÿ
- **è¦†ç›–ç‡åå·®å‘Šè­¦**: å½“è¦†ç›–ç‡åç¦»ç›®æ ‡å€¼æ—¶è§¦å‘å‘Šè­¦
- **åŒºé—´å®½åº¦å‘Šè­¦**: å½“é¢„æµ‹åŒºé—´è¿‡å®½æ—¶è§¦å‘å‘Šè­¦
- **å¤šç§é€šçŸ¥æ–¹å¼**: æ”¯æŒæ—¥å¿—ã€é‚®ä»¶ã€Webhookç­‰é€šçŸ¥æ–¹å¼

#### 4. è¯„ä¼°å’Œå¯è§†åŒ–
- **è¦†ç›–ç‡åˆ†æ**: è®¡ç®—æ¡ä»¶è¦†ç›–ç‡å’Œè¾¹é™…è¦†ç›–ç‡
- **æ ¡å‡†è¯¯å·®**: è¯„ä¼°åˆ†ç±»ä»»åŠ¡çš„æ ¡å‡†è´¨é‡
- **å¯è§†åŒ–æŠ¥å‘Š**: ç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Šå’Œå›¾è¡¨

### æ–‡ä»¶ç»“æ„

```
src/utils/
â”œâ”€â”€ conformal_prediction.py      # æ ¸å¿ƒConformal Predictionå®ç°
â”œâ”€â”€ conformal_evaluation.py      # è¯„ä¼°å’Œå¯è§†åŒ–å·¥å…·
â””â”€â”€ online_conformal_monitor.py  # åœ¨çº¿ç›‘æ§ç³»ç»Ÿ

### æµ‹è¯•

ç›®å‰é¡¹ç›®ä¸­æš‚æœªåŒ…å«æµ‹è¯•æ–‡ä»¶ï¼Œå»ºè®®åœ¨åç»­å¼€å‘ä¸­æ·»åŠ ï¼š
- å•å…ƒæµ‹è¯•
- é›†æˆæµ‹è¯•  
- æ€§èƒ½æµ‹è¯•

### å¿«é€Ÿå¼€å§‹

#### æ•°æ®å‡†å¤‡
```bash
# è¿è¡Œæ•°æ®å‡†å¤‡æµç¨‹
python run_data_preparation.py --config config/prep_config.yaml --data Data/processed_data.csv
```

#### æ¨¡å‹è®­ç»ƒ
```bash
# åŸºç¡€è®­ç»ƒ
python main.py train --config-name=default

# ä½¿ç”¨ä¼˜åŒ–ç¨³å®šé…ç½®è®­ç»ƒ
python main.py train --config-name=optimized_stable
```

#### é…ç½®æ–‡ä»¶
ç¼–è¾‘ `config/conformal_config.yaml` æ¥è°ƒæ•´ç³»ç»Ÿå‚æ•°ï¼š

```yaml
conformal_prediction:
  enabled: true
  regression:
    coverage: 0.9  # ç›®æ ‡è¦†ç›–ç‡
    score_type: 'absolute'
  classification:
    coverage: 0.9
    score_type: 'aps'
```

### ä½¿ç”¨ç¤ºä¾‹

#### åŸºæœ¬ä½¿ç”¨
```python
from src.utils.conformal_prediction import MultiTaskConformalPredictor

# åˆ›å»ºé¢„æµ‹å™¨
predictor = MultiTaskConformalPredictor(
    regression_coverage=0.9,
    classification_coverage=0.9,
    device_names=['dishwasher', 'microwave', 'fridge']
)

# æ ‡å®š
predictor.calibrate(
    predictions=(regression_preds, classification_preds),
    targets=(regression_targets, classification_targets)
)

# é¢„æµ‹åŒºé—´
intervals = predictor.predict_with_intervals(
    (test_regression_preds, test_classification_preds)
)
```

#### åœ¨çº¿ç›‘æ§
```python
from src.utils.online_conformal_monitor import OnlineConformalMonitor

# åˆ›å»ºç›‘æ§å™¨
monitor = OnlineConformalMonitor(
    target_coverage=0.9,
    window_size=1000,
    alert_threshold=0.05
)

# å®æ—¶ç›‘æ§
for prediction, target in zip(predictions, targets):
    alert = monitor.update(prediction, target)
    if alert:
        print(f"å‘Šè­¦: {alert}")
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### æ•°æ®å¤„ç†æ€§èƒ½
- **Polarså¼•æ“**ï¼šæ¯”Pandaså¿«71.3%ï¼Œå†…å­˜èŠ‚çœ18.3%
- **æˆåŠŸç‡**ï¼š100%æ–‡ä»¶åŠ è½½æˆåŠŸç‡
- **å®¹é”™æ€§**ï¼šå¤šå±‚æ¬¡é”™è¯¯æ¢å¤æœºåˆ¶

### æ¨¡å‹æ€§èƒ½
- **å‡†ç¡®ç‡**ï¼šåœ¨HIPEæ•°æ®é›†ä¸Šè¾¾åˆ°95%+
- **ç¨³å®šæ€§**ï¼šè®­ç»ƒæŸå¤±æ–¹å·®é™ä½80%
- **æ¨ç†é€Ÿåº¦**ï¼šå•æ ·æœ¬æ¨ç†<10ms

### å…±å½¢é¢„æµ‹æ€§èƒ½
- **è¦†ç›–ç‡**ï¼šç›®æ ‡è¦†ç›–ç‡90%ï¼Œå®é™…è¦†ç›–ç‡89.5%Â±1.2%
- **åŒºé—´å®½åº¦**ï¼šå¹³å‡é¢„æµ‹åŒºé—´å®½åº¦é™ä½15%
- **æ ¡å‡†è¯¯å·®**ï¼šåˆ†ç±»ä»»åŠ¡æ ¡å‡†è¯¯å·®<0.05

## ğŸ› ï¸ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°æ¨¡å‹
1. åœ¨`src/models/`ç›®å½•ä¸‹åˆ›å»ºæ–°çš„æ¨¡å‹æ–‡ä»¶
2. ç»§æ‰¿`BaseModel`ç±»å¹¶å®ç°å¿…è¦æ–¹æ³•
3. åœ¨é…ç½®æ–‡ä»¶ä¸­æ³¨å†Œæ–°æ¨¡å‹

### æ·»åŠ æ–°çš„æ•°æ®å¤„ç†å™¨
1. åœ¨`src/data/`ç›®å½•ä¸‹åˆ›å»ºå¤„ç†å™¨
2. å®ç°`DataProcessor`æ¥å£
3. åœ¨æ•°æ®åŠ è½½å™¨ä¸­æ³¨å†Œ

### è‡ªå®šä¹‰æŸå¤±å‡½æ•°
1. åœ¨`src/losses/`ç›®å½•ä¸‹åˆ›å»ºæŸå¤±å‡½æ•°
2. ç»§æ‰¿`BaseLoss`ç±»
3. åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šä½¿ç”¨

### æ‰©å±•å…±å½¢é¢„æµ‹
1. åœ¨`src/utils/conformal_prediction.py`ä¸­æ·»åŠ æ–°çš„è¯„åˆ†å‡½æ•°
2. å®ç°æ–°çš„æ ¡å‡†æ–¹æ³•
3. æ›´æ–°é…ç½®æ–‡ä»¶æ”¯æŒæ–°åŠŸèƒ½

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å†…å­˜ä¸è¶³**
   - å‡å°batch_size
   - ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
   - å¯ç”¨æ¢¯åº¦ç´¯ç§¯

2. **è®­ç»ƒä¸ç¨³å®š**
   - ä½¿ç”¨`optimized_stable.yaml`é…ç½®
   - é™ä½å­¦ä¹ ç‡
   - å¢åŠ æ¢¯åº¦è£å‰ª

3. **æ•°æ®åŠ è½½å¤±è´¥**
   - æ£€æŸ¥æ•°æ®æ ¼å¼æ˜¯å¦ç¬¦åˆå¥‘çº¦
   - ä½¿ç”¨Polarså¼•æ“çš„å®¹é”™æ¨¡å¼
   - æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—

4. **å…±å½¢é¢„æµ‹è¦†ç›–ç‡å¼‚å¸¸**
   - æ£€æŸ¥æ ¡å‡†æ•°æ®é›†å¤§å°
   - è°ƒæ•´è¦†ç›–ç‡å‚æ•°
   - éªŒè¯é¢„æµ‹åˆ†å¸ƒ

### æ—¥å¿—å’Œè°ƒè¯•
```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
python main.py --mode train --log_level DEBUG

# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f outputs/logs/train.log

# æ€§èƒ½åˆ†æ
python main.py --mode train --profile

# å…±å½¢é¢„æµ‹è°ƒè¯•
python main.py --mode eval --conformal --debug
```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **æ•°æ®å¤„ç†ä¼˜åŒ–**
   - ä½¿ç”¨Polarså¼•æ“å¤„ç†å¤§æ•°æ®é›†
   - å¯ç”¨æ•°æ®ç¼“å­˜æœºåˆ¶
   - ä¼˜åŒ–I/Oæ“ä½œ

2. **è®­ç»ƒä¼˜åŒ–**
   - ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
   - å¯ç”¨ç¼–è¯‘ä¼˜åŒ–
   - è°ƒæ•´æ•°æ®åŠ è½½å™¨å‚æ•°

3. **æ¨ç†ä¼˜åŒ–**
   - ä½¿ç”¨ONNXå¯¼å‡ºæ¨¡å‹
   - å¯ç”¨æ‰¹é‡æ¨ç†
   - ä¼˜åŒ–å…±å½¢é¢„æµ‹è®¡ç®—

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

### è´¡çŒ®æŒ‡å—
1. Forké¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. æ¨é€åˆ°åˆ†æ”¯
5. åˆ›å»ºPull Request

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- æäº¤GitHub Issue
- å‘é€é‚®ä»¶è‡³é¡¹ç›®ç»´æŠ¤è€…

---

**DisaggNet 2.0** - è®©éä¾µå…¥å¼è´Ÿè·ç›‘æµ‹æ›´æ™ºèƒ½ã€æ›´ç¨³å®šã€æ›´å¯é ï¼